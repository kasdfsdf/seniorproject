{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasdfsdf/seniorproject/blob/main/data%20collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KFkJdWPZXGG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P21FsuV8UEx"
      },
      "outputs": [],
      "source": [
        "!pip install praw\n",
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PCt2JXgG_Ys"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade numpy pandas scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6caHLLR-CJ4X"
      },
      "outputs": [],
      "source": [
        "pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK1aSbhBcb20"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "from datetime import datetime\n",
        "import tweepy\n",
        "import time\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import math\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.feature_extraction.text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prvf81imgKL7"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz_TlBC2CeIa"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "tokenizer = ToktokTokenizer()\n",
        "from nltk.corpus import stopwords\n",
        "stopword_list = stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoAqgL1QeM9K"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDeWOhqMDg7f"
      },
      "outputs": [],
      "source": [
        "# Reddit instance\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"IfcTjjt_BRBs9g\",\n",
        "    client_secret=\"Qy6_w-ylNnyrdeIpCIkmKnve8j-VXA\",\n",
        "    user_agent=\"bigdata2021\",\n",
        ")\n",
        "\n",
        "# Subreddit instance\n",
        "nfl_sub = reddit.subreddit('nfl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5R7T6LMD1N8"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"baltimore OR ravens\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"baltimore\" in comment.body.lower() or \"ravens\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"ravens_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")\n",
        "\n",
        "files.download('ravens_comments_1000.csv')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWfT-S_303ZR"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"pittsburgh OR steelers\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"pittsburgh\" in comment.body.lower() or \"steelers\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"steelers_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")\n",
        "\n",
        "files.download('steelers_comments_1000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvOGMrcN1kcv"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"cincinatti OR bengals\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"cincinatti\" in comment.body.lower() or \"bengals\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"bengals_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")\n",
        "\n",
        "files.download('bengals_comments_1000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFDwzdJqEM9U"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"cincinatti OR bengals\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"cincinatti\" in comment.body.lower() or \"bengals\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"bengals_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IGB1QI6MFz5p"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"cleveland OR browns\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"cleveland\" in comment.body.lower() or \"browns\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"browns_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")\n",
        "\n",
        "files.download('browns_comments_1000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMAEwCkCF_Dr"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"buffalo OR bills\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"buffalo\" in comment.body.lower() or \"bills\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"bills_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIbgUAS0GG_C"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"jets\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"jets\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"jets_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "amodaq6vGiOS"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"miami OR dolphins\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"dolphins\" in comment.body.lower() or \"miami\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"bills_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt-2MZDiGp3l"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"new england OR patriots OR pats\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"new england\" in comment.body.lower() or \"patriots\" in comment.body.lower() or \"pats\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"patriots_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4Cdy--nHQa2"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"kansas city OR chiefs OR KC\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"kansas city\" in comment.body.lower() or \"chiefs\" in comment.body.lower() or \"KC\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"chiefs_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iThLgL1BHcXv"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"denver OR broncos\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"denver\" in comment.body.lower() or \"broncos\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"broncos_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiwirY2QHiql"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"raiders OR las vegas\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"raiders\" in comment.body.lower() or \"las vegas\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"raiders_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJLqXcxIHpmo"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"chargers\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"chargers\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"chargers_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqxlNdeaINYV"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"houston OR texans\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"houston\" in comment.body.lower() or \"texans\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"texans_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RG6CSlKI-Oe"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"tennessee OR titans\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"tennessee\" in comment.body.lower() or \"titans\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"titans_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjbFZXekJGqM"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"indy OR indianapolis or colts\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"colts\" in comment.body.lower() or \"indianapolis\" in comment.body.lower() or \"indy\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"colts_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beBR8YIPJLng"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"philadelphia OR eagles OR philly\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"philadelphia\" in comment.body.lower() or \"eagles\" in comment.body.lower() or \"philly\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"eagles_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNr_6U5TPBvU"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"washington OR commanders OR redskins\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"commanders\" in comment.body.lower() or \"washington\" in comment.body.lower() or \"redskins\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"commanders_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEvkNcb9QZZD"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"giants\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"giants\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"giants_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHBPe7DqQhZ1"
      },
      "outputs": [],
      "source": [
        "comments_data = []\n",
        "count = 0  # Track how many comments we've collected\n",
        "max_comments = 50000  # We want 1,000 comments\n",
        "\n",
        "# Search for posts\n",
        "for submission in reddit.subreddit(\"nfl\").search(\"dallas OR cowboys\", sort='hot', time_filter='all', limit=None):\n",
        "    submission.comments.replace_more(limit=30)  # Skip 'more comments' entries\n",
        "\n",
        "    # Loop through all comments in the submission\n",
        "    for comment in submission.comments.list():\n",
        "        if count >= max_comments:  # Stop when we reach 1,000 comments\n",
        "            break\n",
        "\n",
        "        # Check if \"baltimore\" or \"ravens\" is in the comment body (case-insensitive)\n",
        "        if \"cowboys\" in comment.body.lower() or \"dallas\" in comment.body.lower():\n",
        "            comments_data.append([comment.body])  # Add comment to the list\n",
        "            count += 1\n",
        "\n",
        "    if count >= max_comments:  # Stop processing once we have 1,000 comments\n",
        "        break\n",
        "\n",
        "# Convert collected comments to a DataFrame (single column)\n",
        "df = pd.DataFrame(comments_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv(\"cowboys_comments_1000.csv\", index=False)\n",
        "print(f\"Collected {len(df)} comments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvCqMuniEeVD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOneAcCEFxQAgD5Wc1YUADS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}